<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">














<meta name="google-site-verification" content="YhQFNfa938WU3gqQjb_AsSSrrXve2NXmQwUsYm9a-js">



  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="TensorFlow’s Object Detection API gives access to anyone who wants to quickly create a image/video recognition software. I will be building a coin counter to detect if there is a coin in the image and">
<meta property="og:type" content="article">
<meta property="og:title" content="A Coin Counter with TensorFlow API and OpenCV">
<meta property="og:url" content="http://yoursite.com/2019/11/19/object_detection/index.html">
<meta property="og:site_name" content="Yifeng&#39;s Notebook">
<meta property="og:description" content="TensorFlow’s Object Detection API gives access to anyone who wants to quickly create a image/video recognition software. I will be building a coin counter to detect if there is a coin in the image and">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://i.ibb.co/wwgYtX7/35028879540694746.jpg">
<meta property="og:image" content="https://i.ibb.co/SssJyFt/3768238625917334.jpg">
<meta property="og:image" content="https://i.ibb.co/7nCXpvX/objectdetection-1.png">
<meta property="og:image" content="https://i.ibb.co/qCqZQ1c/2019-11-21-111721.jpg">
<meta property="og:image" content="https://i.ibb.co/rsWVbr2/2019-11-22-223405.jpg">
<meta property="og:image" content="https://i.ibb.co/HGpFcwW/out.png">
<meta property="og:image" content="https://i.ibb.co/HH7sZrr/2019-11-22-234629.jpg">
<meta property="og:image" content="https://i.ibb.co/ZdWCXRb/67876047806213.jpg">
<meta property="og:updated_time" content="2019-11-23T05:12:48.110Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Coin Counter with TensorFlow API and OpenCV">
<meta name="twitter:description" content="TensorFlow’s Object Detection API gives access to anyone who wants to quickly create a image/video recognition software. I will be building a coin counter to detect if there is a coin in the image and">
<meta name="twitter:image" content="https://i.ibb.co/wwgYtX7/35028879540694746.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/11/19/object_detection/">





  <title>A Coin Counter with TensorFlow API and OpenCV | Yifeng's Notebook</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yifeng's Notebook</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/19/object_detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yifeng Li">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yifeng's Notebook">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">A Coin Counter with TensorFlow API and OpenCV</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-19T21:59:36-05:00">
                2019-11-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>TensorFlow’s Object Detection API gives access to anyone who wants to quickly create a image/video recognition software. I will be building a coin counter to detect if there is a coin in the image and calculate the total amount of money simultaneously(see full code on <a href="https://github.com/A3M4/A-Coin-Counter-with-TensorFlow-Object-Detection-API" target="_blank" rel="noopener">https://github.com/A3M4/A-Coin-Counter-with-TensorFlow-Object-Detection-API</a>). The following pictures show the prototype’s results, and future improvements of this project will be discussed in the end of this article.</p>
<img src="https://i.ibb.co/wwgYtX7/35028879540694746.jpg" alt="avatar" style="zoom: 200%;">

<img src="https://i.ibb.co/SssJyFt/3768238625917334.jpg" alt="avatar" style="zoom: 200%;">

<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>TensorFlow-GPU is quite faster than CPU for the training process, but it only supports NVIDIA GPU, this criterion is not met on my laptop. Therefore I chose TensorFlow-CPU and a lot of time was sacrificed to meet a good result. The newest TensorFlow  CPU version(2.0) has some incompatibilities with the object detection models, after trying different versions, TensorFlow 1.15.0 is the most appropriate version to use with my environment(Python3.7.0, Win10-x64). The diagram below shows the workflow for this project.</p>
<img src="https://i.ibb.co/7nCXpvX/objectdetection-1.png" alt="avatar" style="zoom: 200%;">

<br>

<h1 id="Configuring-the-Environment"><a href="#Configuring-the-Environment" class="headerlink" title="Configuring the Environment"></a>Configuring the Environment</h1><p>Tensorflow can be installed by typing the following code in Command Prompt window under C:\ directory:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --upgrade tensorflow==1.15.0</span><br></pre></td></tr></table></figure>

<p>TensorFlow Object Detection API readme installation instructions can be found on <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md</a>, follow this readme to install required dependencies. One thing to note is that it doesn’t show protobuf-compiler installation for windows users, you can find the zip file on <a href="https://github.com/protocolbuffers/protobuf/releases" target="_blank" rel="noopener">https://github.com/protocolbuffers/protobuf/releases</a>. Then clone the TensorFlow models repository(<a href="https://github.com/tensorflow/models" target="_blank" rel="noopener">https://github.com/tensorflow/models</a>) and save it under the same directory with TensorFlow.</p>
<p>In the directory”models\research\object_detection\protos”, there are a lot files ending in .proto. These files can be transferred into *.py by protobuf-compiler, navigate into models\research and type the following command line(protoc directory must be set in PATH in system variables):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protoc-3.10.1-win64\bin\protoc.exe object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>

<p>After finishing compiling, there will be a corresponding .py file for every .proto file under the protos directory. Before going through next step, add a variable in system variables with the name PYTHONPATH and then add those values below to PYTHONPATH:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">C:\TensorFlow\models</span><br><span class="line"></span><br><span class="line">C:\TensorFlow\models\research</span><br><span class="line"></span><br><span class="line">C:\TensorFlow\models\research\slim</span><br><span class="line"></span><br><span class="line">C:\TensorFlow\models\research\object_detection</span><br><span class="line"></span><br><span class="line">C:\Users\Python\python37</span><br></pre></td></tr></table></figure>

<p>Then add %PYTHONPATH% into PATH variable. Now the environment is prepared appropriately. Use Jupyter Notebook to open the file named object_detection_tutorial.ipynb in “models\research\object_detection”, click on the Jupyter toolbar and select the Run All, you should see two sample images when the program stops.</p>
<br>

<h1 id="Labelling-and-Creating-Dataset"><a href="#Labelling-and-Creating-Dataset" class="headerlink" title="Labelling and Creating Dataset"></a>Labelling and Creating Dataset</h1><p>In order not to confuse the model and save time, the tail side of Canadian $1 and $2 coin was used for this project, and a total of 428 pictures in various backgrounds were taken and compressed into smaller size around 300kb. </p>
<p><strong>LabelImg</strong> is a easy-to-use graphical image annotation tool, it can be downloaded on <a href="https://tzutalin.github.io/labelImg/" target="_blank" rel="noopener">https://tzutalin.github.io/labelImg/</a>. The user interface is shown below, just open a directory of saved images, then use Create RecBox at the left side to select coins and label it then click save.</p>
<img src="https://i.ibb.co/qCqZQ1c/2019-11-21-111721.jpg" alt="avatar" style="zoom: 200%;">

<p>when finishes and a XML file containing coordinate data will be generated for each corresponding JPG file.  the part of XML file should look like this:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">-&lt;object&gt;</span><br><span class="line">&lt;name&gt;Toonie&lt;/name&gt;</span><br><span class="line">&lt;pose&gt;Unspecified&lt;/pose&gt;</span><br><span class="line">&lt;truncated&gt;0&lt;/truncated&gt;</span><br><span class="line">&lt;difficult&gt;0&lt;/difficult&gt;</span><br><span class="line"></span><br><span class="line">-&lt;bndbox&gt;</span><br><span class="line">&lt;xmin&gt;205&lt;/xmin&gt;</span><br><span class="line">&lt;ymin&gt;156&lt;/ymin&gt;</span><br><span class="line">&lt;xmax&gt;344&lt;/xmax&gt;</span><br><span class="line">&lt;ymax&gt;299&lt;/ymax&gt;</span><br><span class="line"></span><br><span class="line">&lt;/bndbox&gt;</span><br><span class="line">&lt;/object&gt;</span><br><span class="line"></span><br><span class="line">-&lt;object&gt;</span><br><span class="line">&lt;name&gt;Toonie&lt;/name&gt;</span><br><span class="line">&lt;pose&gt;Unspecified&lt;/pose&gt;</span><br><span class="line">&lt;truncated&gt;0&lt;/truncated&gt;</span><br><span class="line">&lt;difficult&gt;0&lt;/difficult&gt;</span><br><span class="line"></span><br><span class="line">-&lt;bndbox&gt;</span><br><span class="line">&lt;xmin&gt;225&lt;/xmin&gt;</span><br><span class="line">&lt;ymin&gt;369&lt;/ymin&gt;</span><br><span class="line">&lt;xmax&gt;365&lt;/xmax&gt;</span><br><span class="line">&lt;ymax&gt;509&lt;/ymax&gt;</span><br><span class="line"></span><br><span class="line">&lt;/bndbox&gt;</span><br><span class="line">&lt;/object&gt;</span><br><span class="line">&lt;/annotation&gt;</span><br></pre></td></tr></table></figure>

<p>From the above code, it is clear that two Toonies are labeled in the bndbox, and the four three-digit numbers represent the coordinates of four corners of the bndbox. After the labelling, create a “training_images” folder and a “test_images” folder, then copy all the pictures and XML files into “training_images” and randomly select and move 10 pictures of loonie and 10 pictures of toonie into “test_images”.</p>
<img src="https://i.ibb.co/rsWVbr2/2019-11-22-223405.jpg" alt="avatar" style="zoom: 200%;">

<p>The next step(use xml_to_csv.py) is generating two CSV files(one for training and one for testing) from XML files, of which the part of data table as pictured above. This is primarily performed by <strong>xml.etree.ElementTree</strong>, which is a powerful module implementing a efficient API for parsing and creating XML data. The following function uses <strong>glob.glob</strong> to return all paths of XML files and  <strong>xml.etree.ElementTree</strong> to parse them, then save the data into pandas’ dataframe with eight columns, each row represents a coin’s position.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml_to_csv</span><span class="params">(path)</span>:</span></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">'/*.xml'</span>):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">'object'</span>):</span><br><span class="line">            value = (root.find(<span class="string">'filename'</span>).text, int(root.find(<span class="string">'size'</span>)[<span class="number">0</span>].text), int(root.find(<span class="string">'size'</span>)[<span class="number">1</span>].text), member[<span class="number">0</span>].text,</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">0</span>].text), int(member[<span class="number">4</span>][<span class="number">1</span>].text), int(member[<span class="number">4</span>][<span class="number">2</span>].text), int(member[<span class="number">4</span>][<span class="number">3</span>].text))</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">'filename'</span>,<span class="string">'width'</span>,<span class="string">'height'</span>,<span class="string">'class'</span>,<span class="string">'xmin'</span>,<span class="string">'ymin'</span>,<span class="string">'xmax'</span>,<span class="string">'ymax'</span>]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br></pre></td></tr></table></figure>

<p>After that, use generate_tfrecords.py to create two tfrecord files. Run the script and check “C:\TensorFlow_Tut_3_Object_Detection_Walk-through-master\training_data”, there should be two files called eval.tfrecord and train.tfrecord. Besides, label_map.pbtxt should be edited based on the object you want to train. For the purposes of this article, the label_map.pbtxt file looks like this:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">item &#123;</span><br><span class="line">  id: 1</span><br><span class="line">  name: &apos;Toonie&apos;</span><br><span class="line">  display_name: &apos;Toonie&apos;</span><br><span class="line">&#125;</span><br><span class="line">item &#123;</span><br><span class="line">  id: 2</span><br><span class="line">  name: &apos;Loonie&apos;</span><br><span class="line">  display_name: &apos;Loonie&apos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The final part of this section is to choose a model from the Tensorflow detection model zoo(<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md</a>), more than 20 pre-trained models are listed on this link. The <strong>ssd_inception_v2_coco</strong> is usually a good choice for images with different objects, which is the one used in this project(as for dynamic object like webcam or video, <strong>ssd_mobilenet_v1_coco</strong> is the right one to use). Download this model to the repository directory and extract it. </p>
<p><strong>ssd_inception_v2_coco.config</strong> can be found on <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_inception_v2_coco.config" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_inception_v2_coco.config</a>. Save it into the repository directory and  edit the path in train_input_reader and eval_input_reader to the corresponding path of tfrecord.  So far, the preparing process is completed and ready to train.</p>
<br>

<h1 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h1><p><strong>Batch_size</strong> in the config file means the number of images you feed to train at a time, which influences the training time and gradient shifts. It might return error like “<em>Allocation of X exceeds 10% of system memory</em>“ if the number is too large. For the best performance batch size, there is no general principle to follow, you can try different batch sizes within short steps and pick one works best.  </p>
<p>The number of steps is defined as: <strong>num_steps</strong>=(epoch*examples)/batch_size. Therefore, epoch is a definite number defined by the other three variables and one epoch represents a complete round of using all training data for calculation and optimizations.</p>
<p>In consideration of computing power of ordinary laptops and  time costs, <strong>batch_size: 20</strong> and <strong>num_steps: 18000</strong> is set in <strong>ssd_inception_v2_coco.config</strong>. In this case, it usually takes around 40 hours for ordinary PCs to finish the job. After running train.py, the dataset returned by the script is plotted onto a scatter diagram. The plot below has 18000 dots, each dot shows the value of <strong>Loss</strong> on certain <strong>Step</strong>, it has fast convergence before 2500 steps. After that, the speed of decreasing of loss becomes slow, but the model is still becoming more accurate. Generally, the lower the Loss, the higher the model’s accuracy, for this training, the final value of loss remains stable around 0.6 to 1.0.  <img src="https://i.ibb.co/HGpFcwW/out.png" alt="avatar" style="zoom: 200%;"></p>
<br>

<h1 id="Testing-the-Model"><a href="#Testing-the-Model" class="headerlink" title="Testing the Model"></a>Testing the Model</h1><p>Model.ckpt will be generated when train.py finishes running, this file is used for producing inference graph by running export_inference_graph.py. In the test.py file, the block of code below is added to put text on graphs:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">coin = [category_index.get(value) <span class="keyword">for</span> index, value <span class="keyword">in</span> enumerate(classes[<span class="number">0</span>]) <span class="keyword">if</span> scores[<span class="number">0</span>,         index] &gt; <span class="number">0.75</span>]</span><br><span class="line">ToonieCount = []</span><br><span class="line">LoonieCount = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, int(len(coin))):</span><br><span class="line">    <span class="keyword">if</span> str(coin[i][<span class="string">'name'</span>]) == <span class="string">"Toonie"</span>:</span><br><span class="line">        ToonieCount.append(<span class="string">"t"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        LoonieCount.append(<span class="string">"l"</span>)</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Singular &amp; Plural</span></span><br><span class="line">toonie = <span class="string">" Toonies"</span></span><br><span class="line">loonie = <span class="string">" Loonies"</span></span><br><span class="line"><span class="keyword">if</span> len(ToonieCount) &lt;= <span class="number">1</span>:</span><br><span class="line">    toonie = <span class="string">" Toonie"</span></span><br><span class="line"><span class="keyword">if</span> len(LoonieCount) &lt;= <span class="number">1</span>:</span><br><span class="line">    loonie = <span class="string">" Loonie"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add text to image               </span></span><br><span class="line">text = <span class="string">"You have "</span> + str(len(ToonieCount)) + toonie + <span class="string">" and "</span> + str(len(LoonieCount)) +           loonie + <span class="string">", "</span> + str(len(ToonieCount)+len(ToonieCount)+len(LoonieCount)) + <span class="string">" Bucks         in Total."</span></span><br><span class="line">                    </span><br><span class="line">cv2.putText(img=Image_Coin_Counter, text=text, org=(<span class="number">10</span>, <span class="number">50</span>),</span><br><span class="line">            fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=<span class="number">1.1</span>, </span><br><span class="line">            color=[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], lineType=<span class="number">4</span>, thickness=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">cv2.putText(img=Image_Coin_Counter, text=text, org=(<span class="number">10</span>, <span class="number">50</span>),</span><br><span class="line">            fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=<span class="number">1.1</span>, </span><br><span class="line">            color=[<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>], lineType=<span class="number">4</span>, thickness=<span class="number">2</span>)</span><br><span class="line">                            </span><br><span class="line">cv2.imwrite(TEST_IMAGE_DIR + <span class="string">r'/'</span> + str(random.random())[<span class="number">2</span>:] + <span class="string">r'.jpg'</span>, 			                 Image_Coin_Counter)</span><br></pre></td></tr></table></figure>

<p>On the first line, coin defines a list of dictionaries, each dictionary represents an object that has been detected, for an example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">'id'</span>: <span class="number">1</span>, <span class="string">'name'</span>: <span class="string">'Toonie'</span>&#125;, &#123;<span class="string">'id'</span>: <span class="number">2</span>, <span class="string">'name'</span>: <span class="string">'Loonie'</span>&#125;]</span><br></pre></td></tr></table></figure>

<p>This list is used to count the number of coins and decide whether nouns are plural or singular. </p>
<p>Create a folder called “final_test_images” and move the original photos you want to test into it before running test.py. Up to now, the repository directory we are working with looks like the picture below:</p>
<img src="https://i.ibb.co/HH7sZrr/2019-11-22-234629.jpg" alt="avatar" style="zoom: 100%;">

<p>Through testing, it can be found that the model is smart enough to detect the head side of both coins even if it was trained only using the tail side of coins:</p>
<img src="https://i.ibb.co/ZdWCXRb/67876047806213.jpg" alt="avatar" style="zoom: 200%;">

<br>

<h1 id="Future-Improvements"><a href="#Future-Improvements" class="headerlink" title="Future Improvements"></a>Future Improvements</h1><p>Firstly, in order to put the model into practical application, different variety of coins must be included in training, including commemorative coins, paper currency and foreign currency. API or web crawler can be used for calculating real time exchange rates.</p>
<p>Secondly, a much larger range of data is desirable for accuracy in creating a coin counter, 428 pictures are far from perfect. And, more pictures of overlapped coins need to be collected for a better accuracy in the case of various coins overlap with each other. </p>
<p>At last, it is obviously that more training steps will give a better result, it takes time on personal computer   so the training part can be running on a remote server with strong computing capability.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/10/30/WebCrawl/" rel="next" title="Scraping Job Information using Scrapy and Visualizing its Data">
                <i class="fa fa-chevron-left"></i> Scraping Job Information using Scrapy and Visualizing its Data
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/12/10/emoji/" rel="prev" title="Github Emoji">
                Github Emoji <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Yifeng Li</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5gg62scx48x&amp;m=0&amp;c=007eff&amp;cr1=00fff6&amp;f=arial&amp;l=0" async="async"></script>
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Configuring-the-Environment"><span class="nav-number">2.</span> <span class="nav-text">Configuring the Environment</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Labelling-and-Creating-Dataset"><span class="nav-number">3.</span> <span class="nav-text">Labelling and Creating Dataset</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Training-the-Model"><span class="nav-number">4.</span> <span class="nav-text">Training the Model</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Testing-the-Model"><span class="nav-number">5.</span> <span class="nav-text">Testing the Model</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Future-Improvements"><span class="nav-number">6.</span> <span class="nav-text">Future Improvements</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yifeng Li</span>

  
</div>









        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
